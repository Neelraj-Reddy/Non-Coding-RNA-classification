{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, MaxPooling1D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(r'E:\\4th sem\\IOBS-2\\project\\Non Coding RNA classification\\Cleaned_data\\EIIP\\0-100_features.csv')\n",
    "y = pd.read_csv(r\"E:\\4th sem\\IOBS-2\\project\\Non Coding RNA classification\\Cleaned_data\\EIIP\\0-100_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "filters = 64\n",
    "kernel_size = 5\n",
    "growth_rate = 32\n",
    "num_layers_per_block = 3\n",
    "pool_size = 2\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Define the model architecture\n",
    "inputs = Input(shape=(100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes: (1306, 100) (1306, 1)\n",
      "Test set shapes: (73, 100) (73, 1)\n",
      "Validation set shapes: (73, 100) (73, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train (80%) and combined test/validation (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "# Split combined test/validation into test (10%) and validation (10%)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.50, shuffle=True, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"Train set shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shapes:\", X_test.shape, y_test.shape)\n",
    "print(\"Validation set shapes:\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neelr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\neelr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\neelr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder and transform labels to integers\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# Convert integer labels to one-hot encoded labels\n",
    "y_train = to_categorical(y_train_encoded)\n",
    "y_test = to_categorical(y_test_encoded)\n",
    "y_val = to_categorical(y_val_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_130 (Conv1D)         (None, 100, 64)           384       \n",
      "                                                                 \n",
      " batch_normalization_133 (B  (None, 100, 64)           256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_133 (Activation  (None, 100, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_131 (Conv1D)         (None, 100, 192)          37056     \n",
      "                                                                 \n",
      " batch_normalization_134 (B  (None, 100, 192)          768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_134 (Activation  (None, 100, 192)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPooli  (None, 50, 192)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 9600)              0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 128)               1228928   \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1271916 (4.85 MB)\n",
      "Trainable params: 1271404 (4.85 MB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "# Initial convolutional layer\n",
    "x = Conv1D(filters, kernel_size=kernel_size, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Dense blocks\n",
    "def dense_block(x, growth_rate, num_layers):\n",
    "    for _ in range(num_layers):\n",
    "        # Bottleneck layer\n",
    "        bottleneck = BatchNormalization()(x)\n",
    "        bottleneck = Activation('relu')(bottleneck)\n",
    "        bottleneck = Conv1D(filters=growth_rate, kernel_size=1, padding='same')(bottleneck)\n",
    "\n",
    "        # Composite function: BN + ReLU + 3x3 Conv\n",
    "        x = BatchNormalization()(bottleneck)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv1D(filters=growth_rate, kernel_size=3, padding='same')(x)\n",
    "\n",
    "        # Concatenate the output of the composite function with the input to the block\n",
    "        x = Concatenate(axis=-1)([x, bottleneck])\n",
    "    return x\n",
    "\n",
    "# x = dense_block(x, growth_rate, num_layers_per_block)\n",
    "# x = dense_block(x%10, growth_rate, num_layers_per_block)\n",
    "\n",
    "# Additional convolutional layer\n",
    "# x = Conv1D(filters * 2, kernel_size=3, padding='same')(x)  # Double filters after dense blocks\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "# Additional convolutional layer\n",
    "x = Conv1D(filters * 3 , kernel_size=3, padding='same')(x)  # Double filters after dense blocks\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "# Additional layers\n",
    "x = MaxPooling1D(pool_size=pool_size)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(12, activation='softmax')(x)  # Assuming you have 12 classes\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "41/41 [==============================] - 2s 18ms/step - loss: 2.5958 - accuracy: 0.3476 - val_loss: 2.4402 - val_accuracy: 0.2740\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 1.3643 - accuracy: 0.5513 - val_loss: 2.4229 - val_accuracy: 0.0685\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.1725 - accuracy: 0.5995 - val_loss: 2.4473 - val_accuracy: 0.0685\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 1.0160 - accuracy: 0.6593 - val_loss: 2.6068 - val_accuracy: 0.0685\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.9827 - accuracy: 0.6623 - val_loss: 2.6078 - val_accuracy: 0.1370\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.8945 - accuracy: 0.7037 - val_loss: 2.7489 - val_accuracy: 0.0685\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.8680 - accuracy: 0.6945 - val_loss: 2.6930 - val_accuracy: 0.1507\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.7765 - accuracy: 0.7420 - val_loss: 2.8990 - val_accuracy: 0.1507\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.7278 - accuracy: 0.7611 - val_loss: 2.8837 - val_accuracy: 0.1370\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.6659 - accuracy: 0.7665 - val_loss: 2.8804 - val_accuracy: 0.1507\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.6386 - accuracy: 0.7779 - val_loss: 1.7628 - val_accuracy: 0.4110\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - 1s 17ms/step - loss: 0.6389 - accuracy: 0.7864 - val_loss: 1.7140 - val_accuracy: 0.4384\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5730 - accuracy: 0.7986 - val_loss: 1.8856 - val_accuracy: 0.4247\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.5804 - accuracy: 0.8017 - val_loss: 1.3653 - val_accuracy: 0.5753\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.5048 - accuracy: 0.8208 - val_loss: 1.0139 - val_accuracy: 0.6849\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - 1s 19ms/step - loss: 0.5025 - accuracy: 0.8323 - val_loss: 1.3920 - val_accuracy: 0.6301\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4851 - accuracy: 0.8415 - val_loss: 1.1305 - val_accuracy: 0.6712\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.4549 - accuracy: 0.8384 - val_loss: 1.2767 - val_accuracy: 0.6986\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - 1s 16ms/step - loss: 0.4420 - accuracy: 0.8545 - val_loss: 1.1213 - val_accuracy: 0.7534\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.4172 - accuracy: 0.8560 - val_loss: 0.9942 - val_accuracy: 0.7671\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9841 - accuracy: 0.7397\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
